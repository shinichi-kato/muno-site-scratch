---
title: "夢の話ボット"
color: "secondary"
updated: "2022-07-29T12:00Z"
featuredImage: "./cascade.jpg"
tags: 
    - "Tag Decoder"
---

チャットボットの反応をバリエーションに富んだものにすることは重要ですが、人間がさまざまな回答を事前に考えて辞書を作るのは非常に大変な作業です。
そこで<Link to="/article/inside/2-basic/04-text-generation/01-markov">マルコフ連鎖による文生成</Link>を用いてログやコーパスを自動的に辞書化する方法を考えます。

マルコフ連鎖では、直前の一文字を見て次の一文字を決める方法だとログが大きくなるにつれ生成されるテキストが無秩序化してしまう傾向がありますが、連鎖の単位を文字ではなく形態素にしたり、先行する文字を一文字から複数文字にするといった方法でそれを軽減することができる、ということを見てきました。
Fig. 1は<Link to="/article/inside/2-basic/04-text-generation/01-markov">マルコフ連鎖による文生成</Link>で示したものであり、横軸が次候補の数で縦がその頻度を表すヒストグラムで、青がuni-gram(先行する一文字を考慮)、赤がbi-gram(先行する二文字を考慮)です。
これを見ると次候補の数が1である左端のピーク高さはbi-gramで0.7となっており、元の文書を再現する確率が高いことが分かります。また次候補の数が2以上の裾野はbi-gramの方が小さくなっていることからも同様の傾向が見て取れます。
つまりこの方法では無秩序化の軽減が進むと同時に元のテキストの単なる再現に近くなってしまうということで、これではあまり面白くありません。
自然言語としての秩序を保ったままテキスト生成の幅を広げることはできるでしょうか。

![Fig. 1. 二文字を考慮したマルコフ連鎖のヒストグラム](../04-text-generation/2gram.png)

テキストが不自然かどうかを計算することは難しく、例えば鈴木ら[^1]はn-gramに対応したニューラルネットワークを作り、それによる判断を試みています。
しかしマルコフ連鎖で生成したテキストはそもそもn-gramのルールに則っているため、今回の場合は検出力がないと思われます。

[^1]:[鈴井 克徳ら, DEIM Forum 2018 G3-4](https://db-event.jpn.org/deim2018/data/papers/298.pdf)

そこで、上述のページで使ったデータについてテキストが不自然になる状況を具体的に調べてみます。文字のuni-gramだとマルコフ連鎖の中身を見ても意味がわからないので、形態素の1-gramマルコフ連鎖を用います。
マルコフ連鎖うちの次候補の数の多いものを見ると、「の」「を」「が」などがあります。

![Fig. 2. 形態素によるマルコフ連鎖の次候補数](../04-text-generation/morpho-1gram-top.png)

「の」の次候補はこのようになっています。

```
    "の": [
        "侵入",
        "万",
        "融解",
        "意",
        "だ",
        "発する",
        "だ",
        "写真",
        "だ",
        "で"
    ],
```

これらを見ると、「〜の写真」のように一つの概念を構成する単語をつなぐ「の」の他に、強調表現の「のだ」、理由を説明する「ので」のように意味的には分割しないほうが良さそうなものが混在しています。
まずは「のだ」「ので」などは一つのノードとして再構成すると不自然さを軽減する効果があるでしょう。
なお、「のだ」や「ので」における「の」は準体助詞、「〜の写真」における「の」は格助詞に分類されるため、表層語彙だけでなく品詞情報も考慮したマルコフ連鎖の生成も有効です。

次に「を」に続く形態素をみてみましょう。

```
    "を": [
        "知ら",
        "聞き入れ",
        "余儀",
        "伴う",
        "述べる",
        "開示",
        "除い",
        "見合わせ"
    ],
```

こちらは動詞や動詞として機能する名詞（サ変接続名詞）が集まっています。ここで、動詞やサ変接続名詞が集まっているのなら、人間が他の動詞を辞書に付け加えることでチャットボットの反応を拡張できそうです。
ゼロからチャットボットの反応を考えるのに比べて「これ以外の動詞を付け加えて」というお題であれば考えるのは用意になります。
動詞よりももっと膨らませやすそうなのは名詞です。
名詞が現れるパターンを考えると、「りんごが好き」「ライオンが好き」「プリウスが好き」のように、名詞の後に決まったbi-gramが続くものが挙げられます。
さらに「〇〇が好き」パターンに当てはまった〇〇は単に名詞の集合というだけでなく「好みのもの」という一つの概念を形成すると言っても良いかもしれません。
概念化されれば人間は新しい候補をさらに考えやすくなりますし、逆に不適切な候補を除外することも容易になります。

1. 助詞+動詞でノードを再構成
2. 準体助詞関連でノードを再構成
3. 前からマルコフ連鎖を生成
4. 辞書の中で共通する「が好き」を見つけたら「は→Y→が好き」というパターンを「は→(Y→が好き)」に書き換えてYの候補を

* ログをそのまま使う→ログ型

* マルコフ連鎖で何をきっかけに任意のマルコフ連鎖がスタートするのかを決めるのは難しいが、「夢の話」「お告げ」「占い」などの体であればおもしろい
* 小説を使う場合は地の文と発言「」を分離してそれぞれ別のマルコフ連鎖にする→スタックのあるマルコフ連鎖






## タグを展開するエンコーダ
例えば辞書に以下のような記述をします。

```
in:[
    "{animal}"
],
out:[
    "犬","猫","イルカ","アゲハチョウ","恐竜"
],
in:[
    "好きな動物は？"
],
out:[
    "{animal}が好きだよ"
]
```

ここでinやoutのなかで`{animal}`と書かれている部分をタグと呼びます。outの文字列にタグが含まれたらinの中に同じタグを見つけて、その中からランダムに一つを使います。
これにより、「`{animal}`が好きだよ」という辞書の文字列は「犬が好きだよ」「猫が好きだよ」・・・としてユーザへの返答になります。

この処理をするためには

## 辞書の可読性と概念化

ここで、辞書の可読性について考えます。

* 助詞と動詞＋送り仮名、サ変動詞の結合、形態素→句読点の結合
* 文末から文頭に向かうマルコフ連鎖生成。文頭文字を付ける必要があり、
* セリフと地の文の区別



りんごが好き
猫が好き
景色を見るのが好き
猫を見るのが好き

のようにかかり受けが右から左になる場合が多いので、マルコフ連鎖も末尾から先頭に向かって進める
これにより「好きな何か」という概念がマルコフ連鎖の中に形成され、それを人間が後から改造しやすくなる

辞書化する際は

{node001}:["りんご","猫","{node003}を見るの"]
{node002}:["{node001}が好き"]
{node003}:["景色","猫"]

のようになるはず。
