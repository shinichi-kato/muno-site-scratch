---
title: テキスト検索(2) - 形態素解析
color: "secondary"
updated: "2020-05-17T12:00Z"
featuredImage: amethyst.jpg
tags: 
    - "機械学習"
    - "自然言語解析"
---

テキストの類似度を調べる基本的な前処理として**形態素解析**があることを紹介しました。これをチャットボットに組み込む際に考慮すべき点について考えてみます。

### 形態素解析器の強みと弱み

形態素解析は日本語のように単語の区切りが見た目にわからない言語でテキストを単語に区切る目的で行われる処理で、一例として[mecab](https://taku910.github.io/mecab/)でテキストを処理すると以下のような出力を得られます。

```shell-session
$ mecab
フライパンにサラダ油を入れて弱火で熱し、鶏肉の皮側を下にして入れる。
フライパン	名詞,普通名詞,*,*,フライパン,ふらいぱん,代表表記:フライパン/ふらいぱん カテゴリ:人工物-その他 ドメイン:料理・食事
に	助詞,格助詞,*,*,に,に,*
サラダ	名詞,普通名詞,*,*,サラダ,さらだ,代表表記:サラダ/さらだ カテゴリ:人工物-食べ物 ドメイン:料理・食事
油	名詞,普通名詞,*,*,油,あぶら,代表表記:油/あぶら 漢字読み:訓 カテゴリ:自然物
を	助詞,格助詞,*,*,を,を,*
入れて	動詞,*,母音動詞,タ系連用テ形,入れる,いれて,代表表記:入れる/いれる 自他動詞:自:入る/はいる 反義:動詞:出す/だす
弱火	名詞,普通名詞,*,*,弱火,よわび,代表表記:弱火/よわび カテゴリ:自然物 ドメイン:料理・食事
で	助詞,格助詞,*,*,で,で,*
熱し	動詞,*,サ変動詞,基本連用形,熱する,ねっし,代表表記:熱する/ねっする
、	特殊,読点,*,*,、,、,*
鶏肉	名詞,普通名詞,*,*,鶏肉,けいにく,代表表記:鶏肉/けいにく カテゴリ:人工物-食べ物 ドメイン:料理・食事
の	助詞,接続助詞,*,*,の,の,*
皮	名詞,普通名詞,*,*,皮,かわ,代表表記:皮/かわ 漢字読み:訓 カテゴリ:動物-部位;植物-部位
側	接尾辞,名詞性名詞接尾辞,*,*,側,がわ,代表表記:側/がわ
を	助詞,格助詞,*,*,を,を,*
下	名詞,普通名詞,*,*,下,した,代表表記:下/した 漢字読み:訓 カテゴリ:場所-機能
に	助詞,格助詞,*,*,に,に,*
して	動詞,*,サ変動詞,タ系連用テ形,する,して,代表表記:する/する 付属動詞候補（基本） 自他動詞:自:成る/なる
入れる	動詞,*,母音動詞,基本形,入れる,いれる,代表表記:入れる/いれる 自他動詞:自:入る/はいる 反義:動詞:出す/だす
。	特殊,句点,*,*,。,。,*
```

出力結果を見ると品詞や代表表記、同士の場合はその基本形などが取得できています。これを利用すれば、例えば助詞自体にはほとんど意味がないので除去する、とか「熱し」を「熱する」のような基本形に変換することで表記の揺れに強い検索が可能になる、などの効果が期待できます。その一方で課題になるのはサイズと処理速度です。MeCabの場合インストールサイズは219MB程度で、ほとんどの大きさを単語辞書が占めています。またMeCabはC++言語で書かれており非常に高速ですが、古株に属しており精度はまずまずと言われています。それと比べnagisaのような新しい形態素解析器は深層学習を取り入れて高い精度での形態素解析ができますが、速度が遅い傾向があります。  

まとめると、形態素解析器はサーバー側で動作するチャットボットに適した方法で、さらにバイナリーを動かせる環境が用意できることが条件ということになります。

### 分かち書き器の強みと弱み

ここで、品詞の情報を使わないでテキストを単語に区切るだけをすることを**分かち書き**と呼びます。分かち書きを行うモジュールとしては[TinySegmenter](http://chasen.org/~taku/software/TinySegmenter/)があります。TinySegmenterはJavaScriptで書かれており、サイズは25kBです。これほど小さいサイズにできるのは辞書を持っていないことと精度を多少犠牲にしているためです。実際に分かち書きをさせてみると、以下のような結果が出力されます。

```shell-session
フライパン | に | サラダ | 油 | を | 入れ | て | 弱火 | で | 熱し | 、 
| 鶏肉 | の | 皮側 | を | 下に | し | て | 入れる | 。
```
いかがでしょうか。「下」「に」とするべきところを「下に」にしているなどいくつか違いはあるものの、まずまずの精度で分かち書きをしているのが解ると思います。また品詞情報は含まれていません。辞書を使わないため、動作速度はかなり高速です。

まとめると、分かち書きはブラウザ上で動作するチャットボットに適した方法で、精度が低いことが問題にならない設計であることが必要です。実際上は単語への分け方がどのようであっても再現性があれば同じ文書は同じと計算できてしまうので、正確さはあまり求められません。さらに雑談チャットボットはテキスト検索システムとは違って多少違った返答をしても許容されますので、サーバー上でもブラウザ上でも分かち書きで事足りる、ということも多いと考えられます。


### チャットボット向けの分割処理

ここでチャットボット用に検索精度を高める工夫について考えてみます。チャットボットで扱われるテキスト、つまりログは多くの文書よりも短く、省略が多用される傾向があります。通常の文書であれば「てにをは」のような助詞は数多く使われすぎ、また単独では意味がないので無視されるのですが文が短ければそうでもなくなってきます。例えば次に示す２つの文は助詞以外全て同じ単語で構成されていますが意味は全く違っています。

> Aさん: お母さんに怒られたよ  
> Bさん: お母さんが怒られたよ

前者の「お母さん」は目的語で、主語は書かれておらずこの一文だけでは誰かはわかりませんが、Aさん本人がお母さんから怒られた場面は一番ありえそうです。後者の「お母さん」は主語で、お父さんか誰かにお母さんが怒られている様子をBさんが横で目撃した場面はありえそうです。短いテキストではあってもこの２つでずいぶんと状況が異なることがわかります。ちなみに形態素解析ではどちらのお母さんも「名詞」に分類され、主語か目的語かの区別はできません。これを行うためには統語解析・意味解析と呼ばれる処理が必要なのですが、[NPCMJ](http://npcmj.ninjal.ac.jp/)によれば2020年現在継続中の研究プロジェクトとなっています。

また日本語の場合は文節の順番を入れ替えてもある程度意味が通じるという特徴があります。

> お母さんが先生に怒られたよ  
> 先生にお母さんが怒られたよ

テキストの類似度を比べる計算方法では単語の並び順は考慮しないものが多いのですが、日本語のこの特性とは相性が良いかもしれません。以上のことから、チャットボットでは単純な分かち書きをするよりも、助詞がある場合は助詞と名詞をセットにして一つの単語とみなすと良いと考えられます。例えば以下のようなイメージです。

```shell-session
フライパンに | サラダ | 油を | 入れ | て | 弱火で | 熱し | 、 
| 鶏肉の | 皮側を | 下に | し | て | 入れる | 。
```

加えて、助詞自体が省略されてしまったときなどにもある程度検索できるようにすることも考慮して、元の名詞は残すことにします。これをTinySegmenterの後処理として行うようにしましょう。TinySengmenterでは分かち書きの結果は配列に格納されて返されます。

```js
["フライパン" , "に" , "サラダ" , "油" , "を" , "入れ" , "て" , "弱火" , "で" , "熱し" , 、 
, "鶏肉" , "の" , "皮側" , "を" , "下に" , "し" , "て" , "入れる" , "。"]
```

これを先頭から調べて、以下のようなルールで配列の編集を行います。

1. 名詞の後ろに助詞が続いた場合は、「名詞＋品詞」「名詞」という２つの単語に変換する。
1. URIエスケープ文字は一つの単語に変換する。
1. 将来使いそうなチャットボット向けの指令文字列<...>もついでに一つの単語に変換する。

これを実装する一例として、有限オートマトンが使えます。オートマトンを[レイルロードダイアグラム](https://bottlecaps.de/rr/ui)で表現すると以下のようになります。

!["Particle ::= ("が" | "を" | "に" | "は" | "へ" | "で" );Directive ::= "<...>";Text ::= ( "*"^Particle Particle? | Particle | Directive | ("%" ("[0-9][0-9]" | [0-9A-F] [0-9A-F] | "[A-F][A-F]" ) ))+"](./diagram-marked.png)

図中の`*`は`Particle`、`%`、`<...>`以外を示します。  
図のA地点では**ルール1**の処理、図のB地点では**ルール2**の処理を行います。**ルール3**に特別な処理はありませんが、助詞とくっついて予想外の挙動をさせないために別に記述しています。ちなみに`%`を通過したあとの場合分けに`[0-9][0-9]`と`[A-F][A-F]`があってわざわざ分ける必要がなさそうに見えますが、TinySegmenterが連続する数字、連続するアルファベットは一つの単語とみなし、数字とアルファベットが並んでいたら別の単語とみなすためにこのような状態遷移になっています。 

この方法によるテキスト検索は[fairylab-0.7](https://github.com/shinichi-kato/fairylab-0.7)の中でも行っていますので、興味のある方はソースをご確認ください。