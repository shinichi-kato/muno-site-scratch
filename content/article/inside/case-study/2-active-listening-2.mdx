---
title: "傾聴ボット(2)"
color: "secondary"
updated: "2022-07-22T12:00Z"
featuredImage: "./railroad-diagram.png"
tags: 
    - "test"
---

## 要約のためのencoder設計

前の章では傾聴の技法のうち簡易なものを選び、シンプルな構成の傾聴チャットボットを作ってみました。
今回はこれをさらに進め、傾聴のいち技法である**要約**ができるチャットボットを考えます。要約は以下のように話し手の言葉の中で要点になる部分を抽出して話し手に返すことです。

> ユーザ: 今日は隣の街のモールに行って、本屋でマンガを買ってきたよ  
> チャットボット:マンガを？

「話し手の言葉を一部抽出して再利用する」という方法はElizaでも利用されています。その辞書を観察してみましょう。
[Elizaの辞書](https://github.com/wadetb/eliza/blob/master/doctor.txt)では、会話機能の中核部分はキー`key`、分解`decomp`と再構成`reasmb`からなっています。

```yaml
key: remember 5
  decomp: * i remember *
    reasmb: Do you often think of (2) ?
    reasmb: Does thinking of (2) bring anything else to mind ?
    reasmb: What else do you recollect ?
    reasmb: Why do you remember (2) just now ?
    reasmb: What in the present situation reminds you of (2) ?
    reasmb: What is the connection between me and (2) ?
    reasmb: What else does (2) remind you of ?
```

この辞書ではユーザの入力に`key`の`"remeber"`が含まれていた場合、`decomp`のパターンに従って `"i remember"`より前の部分を(1)に、後の部分を(2)に代入します。
続いて`reasmb`のうちどれか一つを選んで(1)や(2)を当てはめて返答とします。
例えばユーザが「**At the moment** I remember **his face**」と言ってきたら、(1)=**At the moment**、(2)=**his face**という抽出を行い、「Do you often think of **his face**」という返答を生成します。
  
これを参考に日本語で一部の単語を抽出するエンコーダーを考えます。
まずはElizaを直訳してみます。

```
in: ["* を思い出しました"],
out: ["(1)を今思い出されたのはどうしてですか？"]
```

この例では「そういえば昔飼っていた犬のことを思い出しました」に対して「そういえば昔飼っていた犬のことを今思い出されたのはどうしてですか？」が返事になってしまい、やや不快感を与える場合があるかもしれません。
こちらの意図としては「犬のことを今思い出したのはどうしてですか？」くらいのボリュームで良いのです。
英語であってもこのやり取りでは少ししつこいように思いますが、日本語の場合は共通認識になっている情報は省略することが望ましいため、一層違和感を覚える返答になってしまいました。
これを踏まえると日本語の場合は*の部分は一文節程度の抽出が良さそうです。そこで、ベクトル化の方法としてbag-of-wordsの代わりにbag-of-文節(phrases)を利用したテキスト検索を行います。


### bag-of-文節エンコーダー
### 文節への分割
文節への分割を利用し、テキスト検索の性能を向上させようという取り組みは様々試みられています[^1] [^2]。
それらの先行研究と比べて今回はかなり簡易な方法になっています。

[^1]: 杉山弘晃ら, ”任意の話題を持つユーザ発話に対する. 係り受けと用例を利用した応答文の生成”, [人工知能学会誌30(1) pp.183-194](https://www.jstage.jst.go.jp/article/tjsai/30/1/30_30_183/_pdf)  
[^2]: 大塚淳史ら, "文構造を考慮した発話理解に基づく自然文検索", [JSAI2016 4B4-6](https://www.jstage.jst.go.jp/article/pjsai/JSAI2016/0/JSAI2016_4B42/_pdf/-char/ja)  


また文節への分割を行うツールも[SpaCy](https://spacy.io/models/ja)など多数存在しますので、それを利用できる環境があれば利用したほうがよいでしょう。
一方で、便利なツールに頼ってしまうと自分のやりたいことをツールの方に合わせてしまったり、内部の挙動や出力の形式を自由にいじれなくなるので、まずは簡単なものを自作してみることも面白いのではないかと思います。
それではエンコーダーの前半部分である**分割部**に注目して、文節に区切るのと形態素に区切るのとの違いを見ていきます。まず文を[UniDic-MeCab](http://www4414uj.sakura.ne.jp/Yasanichi1/unicheck/)で形態素に区切ると

> 米田 | さん | は | 図書館 | に | 傘 | を | 持っ | て | でかけ | た

となります。bag-of-wordsの考え方では語順は無視されるので、語順をランダムに入れ替えた

> は | 図書館 | さん | 米田 | を | 持っ | でかけ | た | て | に | 傘

はベクトル化すると元の文と同じとみなされますが、日本語的には全く意味が変わってしまいます。一方文節に区切ってシャッフルしてみると

> 米田さんは | 図書館に | 急いで | でかけた  
> 図書館に | 急いで | 米田さんは | でかけた   

となり、「米田さんは」「図書館に」「急いで」の３つは入れ替えても文の意味がほとんど変わりません。
このように入れ替えが可能な文節がある一方、順番が決まっている文節もあります。
最後の動詞「でかけた」は位置を変えるとニュアンスが変わりますが、形態素の場合のような支離滅裂さと比べれば意味はかなり保存されているようです。

> 図書館に|でかけた|米田さんは|急いで  
> でかけた|急いで|米田さんは|図書館に  

次に「〜の」という所有や修飾を表す文節はかかり受けの結びつきが強く、順番を入れ替えると意味が大きく変わる傾向があります。

> 隣の|町の|モールに|出かける  
> 街の|隣の|モールに|出かける  

分節化することで順序を入れ替えても意味が壊れにくくなることは確かだと思われますが、実際はどうなのでしょう。
Bag-of-文節の性能を数字で比較するには、異なるトピックについて語られたチャットのログを集め、Bag-of-形態素とBag-of-文節から機械学習モデルを作ってトピック分類を行い、その性能を比較する…というような方法ができるでしょう。
そのあたりはチャットのログを集めることを含めて今後の宿題にします。

性能確認はひとまず置いて、今回文字列をベクトル化する目的は類似度の計算で、対象としているのはチャットで使われる短めで砕けた日本語です。
それを踏まえた場合、述語や修飾を表す文節も含めて融通を効かせても良いかもしれません。

少し遠回りしましたが、つまり日本語の場合は語順に融通が効くとよく言われていますが、もう少し細かく言うと

**文節の順序**は融通がきく

のです。このような特徴と順序を考慮しないbag-of-wordsは非常に相性が良いでしょう。これがbag-of-phrases(文節)の着眼点です。
さて、それぞれの文節の多くは助詞つまり「てにをは」で終わっています。

| 書字形 | 品詞	|
| :--    | :-- |
| 米田 | 名詞-固有名詞-人名-姓 |
| さん | 接尾辞-名詞的-一般 |
| は   | **助詞**-係助詞 |
| 図書 | 名詞-普通名詞-一般 |
| 館   | 接尾辞-名詞的-一般	|
| に   | **助詞**-格助詞 |
| 急い | 動詞-一般 |
| で   | **助詞**-格助詞 |
| でかけ | 動詞-一般 |
| た     | 助動詞 |

それを目印にして、一旦形態素解析された文字列を文節に分けなおします。
そのため形態素解析で得られた品詞情報を使えば精度は高いですが、単純化のため、またブラウザ上でも動かせるようにするためTinySengementerによる分かち書きを利用し、書字形だけで判断することにします。
なお、典型的な文節の分類は主語・述語・修飾語・接続語・独立語の5種類ですが、これは機能の分類であって、あまり意味に立ち入っていません。
テキスト解析ではもっと意味のわかる分類が必要なので、教科書的な考え方にあまりこだわらずに分類を考えていきます。

| 表層         | 出力      | 
| ---          | ---       | 
| X が              | X\t主語   |
| X さん が         | X\t主者   |
| X は              | X\t主語   |
| X さん は         | X\t主者   | 
| X を              | X\t対象語 |
| X さん を         | X\t対象者 | 
| X の こと を      | X\t対象語 | 
| X さん の こと を | X\t対象者 | 
| X に              | X\t目的語 | 
| X さん に         | X\t目的者 | 
| X の              | X\t修飾語 | 
| X さん の         | X\t修飾者 | 
| X な              | X\t修飾語 |
| X だ              | X\t修飾語 |
| X で              | X\t述語   | 
| X する            | X\t述語   |
| X し た           | X\t述語   |
| X による          | X\t手段   |
| しかし            | しかし    | 

さらに上記の表で、「Xさんが」は「Xちゃんが」「X先生が」などでもOKです。
入力文字列はあらかじめ分かち書きされ、形態素のリストになっています。
このリストを調べて表の「表層」に一致する部分があればそれを一つにまとめて「出力」に置き換えます。
Xには助詞以外のどのような形態素が来てもOKです。したがって、

> 藤野先生が新宿の本屋にいる

は

> 藤野先生\t主者 新宿\t修飾語 本屋\t目的語 い る

と変換します。ここまでで説明した分節化処理をBNF記法で表すと以下のようになります。

```
main ::= indep* '*'+ (indep* '*'+)* person_suffix? (subj|obj|dest|mod|by|verb) 'accept()'
subj ::= ('が'|'は'|'と' ) 'subj()'
obj ::= ('を' 'obj()') | ('の' 'mod()' ('こと' ('を' 'obj()'|subj|dest|by) )? )
dest ::= ('に' 'は'?|'まで') 'dest()'
mod ::= ('な'|'だ'|'ね') 'mod()'
by ::= 'で|により|による' 'by()'
verb ::= ('する' | 'し' 'た') 'verb()'

person_suffix::= 'さん'|'君'|'ちゃん'|'先生'
indep::='しかし'|'なので'|'それで'|'、|。|？|！'
```
これは[Railroal Diagram Generator](https://www.bottlecaps.de/rr/ui)にコピー&ペーストすればグラフ化できますので、ぜひ確認してみてください。
このうちメインルーチンに相当するmainは以下のようになります。
![main     ::= ( indep* '*'+ )+ person_suffix? ( subj | obj | dest | mod | by | verb ) 'accept()'](/railroad-diagram.png)

このダイアグラムはプッシュダウン・オートマトンに書き換えることができます。それを実装したデモを以下に示します。

<PhraseSegmenterDemo />


### 7. ベクトル化

上述の文節化により、入力文字列をなんとなく文節に区切ることができました。これを利用して文節の抽出を考えます。

> <span>*</span>を思い出しました → <span>*</span> 対象語 | 思い出し | まし | た  


### 7. 短い要約を返す
(以下製作中)
