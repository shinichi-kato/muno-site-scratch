---
title: "傾聴ボット(2)"
color: "secondary"
updated: "2022-07-12T12:00Z"
featuredImage: "../abstract2.png"
tags: 
    - "test"
---

## 要約のためのencoder設計

前の章では傾聴の技法のうち簡易なものを選び、シンプルな構成の傾聴チャットボットを作ってみました。
今回はこれをさらに進め、傾聴のいち技法である**要約**ができるチャットボットを考えます。要約は以下のように話し手の言葉の中で要点になる部分を抽出して話し手に返すことです。

> ユーザ: 今日は隣の街のモールに行って、本屋でマンガを買ってきたよ  
> チャットボット:マンガを？

「話し手の言葉を一部抽出して再利用する」という方法はElizaでも利用されています。その辞書を観察してみましょう。
[Elizaの辞書](https://github.com/wadetb/eliza/blob/master/doctor.txt)では、会話機能の中核部分はキー`key`、分解`decomp`と再構成`reasmb`からなっています。

```yaml
key: remember 5
  decomp: * i remember *
    reasmb: Do you often think of (2) ?
    reasmb: Does thinking of (2) bring anything else to mind ?
    reasmb: What else do you recollect ?
    reasmb: Why do you remember (2) just now ?
    reasmb: What in the present situation reminds you of (2) ?
    reasmb: What is the connection between me and (2) ?
    reasmb: What else does (2) remind you of ?
```

この辞書ではユーザの入力に`key`の`"remeber"`が含まれていた場合、`decomp`のパターンに従って `"i remember"`より前の部分を(1)に、後の部分を(2)に代入します。
続いて`reasmb`のうちどれか一つを選んで(1)や(2)を当てはめて返答とします。
例えばユーザが「**At the moment** I remember **his face**」と言ってきたら、(1)=**At the moment**、(2)=**his face**という抽出を行い、「Do you often think of **his face**」という返答を生成します。
  
これを参考に日本語で一部の単語を抽出するエンコーダーを考えます。
まずはElizaを直訳してみます。

```
in: ["* を思い出しました"],
out: ["(1)を今思い出されたのはどうしてですか？"]
```

この例では「そういえば昔飼っていた犬のことを思い出しました」に対して「そういえば昔飼っていた犬のことを今思い出されたのはどうしてですか？」が返事になってしまい、やや不快感を与える場合があるかもしれません。
こちらの意図としては「犬のことを今思い出したのはどうしてですか？」くらいのボリュームで良いのです。
英語であってもこのやり取りでは少ししつこいように思いますが、日本語の場合は共通認識になっている情報は省略することが望ましいため、一層違和感を覚える返答になってしまいました。
これを踏まえると日本語の場合は*の部分は一文節の抽出が良さそうです。そこで、ベクトル化の方法としてbag-of-wordsの代わりにbag-of-文節(phrases)を利用したテキスト検索を行います。


#### bag-of-文節エンコーダー

文節に区切るのと形態素に区切るのとの違いを見ていきます。まず文を[UniDic-MeCab](http://www4414uj.sakura.ne.jp/Yasanichi1/unicheck/)で形態素に区切ると

> 米田 | さん | は | 図書館 | に | 傘 | を | 持っ | て | でかけ | た

となります。bag-of-wordsの考え方では語順は無視されるので、語順をランダムに入れ替えた

> は | 図書館 | さん | 米田 | を | 持っ | でかけ | た | て | に | 傘

はベクトル化するともとの文と同じとみなされますが、日本語的には全く意味が変わってしまいます。一方文節に区切ってみると

> 米田さんは | 図書館に | 急いで | でかけた
> 図書館に | 急いで | 米田さんは | でかけた

のように、「米田さんは」「図書館に」「急いで」の３つは入れ替えても文の意味がほとんど変わりません。
一方最後の動詞「でかけた」は位置を変えるとニュアンスが変わりますが、形態素の場合のような支離滅裂さと比べれば意味はかなり保存されているようです。

> 図書館に|でかけた|米田さんは|急いで
> でかけた|急いで|米田さんは|図書館に

つまり日本語の場合は語順に融通が効くとよく言われていますが、より細かく言うと

**文節の順序**は融通がきく

のです。このような特徴と順序を考慮しないbag-of-wordsは非常に相性が良いでしょう。これがbag-of-phrases(文節)の着眼点です。
さて、それぞれの文節の最後は助詞つまり「てにをは」で終わっています。

| 書字形 | 品詞	|
| :--    | :-- |
| 米田 | 名詞-固有名詞-人名-姓 |
| さん | 接尾辞-名詞的-一般 |
| は   | **助詞**-係助詞 |
| 図書 | 名詞-普通名詞-一般 |
| 館   | 接尾辞-名詞的-一般	|
| に   | **助詞**-格助詞 |
| 急い | 動詞-一般 |
| で   | **助詞**-格助詞 |
| でかけ | 動詞-一般 |
| た     | 助動詞 |

それを目印にして、一旦形態素解析された文字列を文節に分けなおします。
そのため形態素解析で得られた品詞情報を使えば精度は高いですが、単純化のため、またブラウザ上でも動かせるようにするためTinySengementerによる分かち書きを利用し、書字形だけで判断することにします。
なお、典型的な文節の分類は主語・述語・修飾語・接続語・独立語の5種類ですが、これは機能の分類であって、あまり意味に立ち入っていません。
テキスト解析ではもっと意味のわかる分類が必要なので、教科書的な考え方にあまりこだわらずに分類を考えていきます。

| 表層         | 出力      | 
| ---          | ---       | 
| X が              | X\t主語   |
| X さん が         | X\t主者   |
| X は              | X\t主語   |
| X さん は         | X\t主者   | 
| X を              | X\t対象語 |
| X さん を         | X\t対象者 | 
| X の こと を      | X\t対象語 | 
| X さん の こと を | X\t対象者 | 
| X に              | X\t目的語 | 
| X さん に         | X\t目的者 | 
| X の              | X\t修飾語 | 
| X さん の         | X\t所有者 | 
| X な              | X\t修飾語 |
| X だ              | X\t修飾語 |
| X で              | X\t述語   | 
| X する            | X\t述語   |
| X し た           | X\t述語   |
| X による          | X\t手段   |
| しかし            | しかし    | 

さらに上記の表で、「Xさんが」は「Xちゃんが」「X先生が」などでもOKです。
入力文字列はあらかじめ分かち書きされ、形態素のリストになっています。
このリストを調べて表の「表層」に一致する部分があればそれを一つにまとめて「出力」に置き換えます。
Xにはどのような形態素が来てもOKです。したがって、

> 藤野 先生 が 新宿 の 本屋 に いる

は

> 藤野\t主者 新宿\t修飾語 本屋\t対象語 い る

と変換します。加えて抽出するべき文節を示す記号として「*」を使いることにし、

> *さんの友達だ

は

> *\t所有者 友達\t修飾語

にします。ここまでで説明した分節化処理をBNF記法で表すと以下のようになります。

```
main ::= indep* '*'+ (indep* '*'+)* person_suffix? (subj|obj|dest|mod|verb)
subj ::= ('が'|'は') 'accept_subj()'
obj ::= ('を' 'accept_obj()') | ('の' 'accept_posses()' ('こと' 'を' 'accept_obj()')? )
dest ::= 'に' 'accept_dest()'
mod ::= 'な' 'accept_mod()'
verb ::= ('する' | 'し' 'た') 'accept_verb()'

person_suffix::= 'さん'|'君'|'ちゃん'|'先生'
indep::='しかし'|'なので'|'それで'
```
これを[Railroal Diagram Generator](https://www.bottlecaps.de/rr/ui)で画像化したものを[こちら](./diagram.xhtml)に示します。

<PhraseSegmenterDemo />


### 7. 短い要約を返す

1〜6を使ったチャットボットでは、例えばユーザ（話し手）の入力文字列が下記inのどれかに似ていたら、outの文字列を返答にするという辞書で作ることができました。

> in: "えーっと、", "うーん", "なんと言ったらいいか"
> out: "ゆっくり考えてもらって大丈夫ですよ。"


この仕掛けは一見すると日本語にも移植できそうに見えますが、日本語では語順に融通が効き、主語をはじめとして両者で共通認識している語は省略することが好まれます。
またtfidfのような統計的な類似度を用いた検索ではなく明確なパターンマッチングによってエンコードを行っているため、対応力はそれほど大きくありません。



(以下製作中)
