---
title: マルコフ連鎖による文生成
color: "secondary"
updated: "2022-10-10T12:00Z"
featuredImage: wordgraph.png
tags: 
    - "テキスト生成"
    - "自然言語解析"
---

 **本ページは現在推敲中です**

以下のテキスト[^1]を素材として、自然言語らしい文字列を自動生成するにはどうしたらよいかを考えます。

```
理由を知らぬ科学者たちが忠告を聞き入れなかったため私はこの陳述を余儀なくされた。
現在意図されている南極への侵入――大規模な化石狩りと大掛かりなボーリング及び太古の
万年氷雪の融解とを伴う計画に反対する理由を述べることは、全く以て私の意に反するのだ。
私の発する警告が無駄になるかもしれないと思うと、尚更気が進まない。
私はリアルな事実を開示しなければならないのだが、それらに対する疑念は当然起こるべき
ものである。だが、途方もないもの、信じ難いものを除いてしまえば後には何一つ残らない
だろう。これまで発表を見合わせてきた写真、通常の写真も航空写真もあるのだが、
それらは忌々しいほど鮮明かつ写実的なので私に味方してくれるはずだ。それでも尚、
それらは巧妙な捏造が可能な遠距離撮影であるため疑われることになろう。
```
[^1]: [H.P.ラヴクラフト「狂気の山脈にて」](https://www.aozora.gr.jp/cards/001699/files/57858_59672.html)より - 青空文庫

## 次の文字は

このテキストに現れる文字をランダムに並べてしまうと、もちろん意味のある言葉は作れそうにありません。
文字を全くランダムに並べるということは、一文字目を選んだあとで一文字目が何かを全く考慮せずに二文字目を選ぶということです。
それに比べるとテキスト中に現れる文字の「次の文字」というのは非常に限られていることが分かります。
試しに上のテキストの全ての文字について、例えば「理→由」のように、ある文字の次に来る文字を矢印で結ぶとFig. 1のようになります。

![Fig. 1. 文字単位のマルコフ連鎖](./1gram-digraph.png)

図中で文字を示す丸が緑〜黄で色分けされていますが、緑になるほど次の候補が少なく、黄色に近いほど次の候補が多いことを示しており、丸の大きさは文字の出現頻度に対応しています。
多くの文字が緑に寄っていて、一文字目が決まると二文字目も決まるというような場合が結構多いことが分かります。
この例のように「ある状態から次に何を選ぶか」を有向グラフで示したものをマルコフ連鎖と呼びます。

Fig. 1を見ると、矢印に従って文字を選び取っていけばかなり自然言語風の文字列が得られそうです。実際にこの方法で得られた文字列の例をひとつ示します。

```
理由を知らな化石狩りとを余儀なボーリング及び太古ので私はずだ。
```
意外とそれらしい文字列ができました。ですがところどころおかしなつながりになっています。
緑の丸が連続していれば、元のテキストをたどることになるので意味のある言葉に見えてきます。
一方、特に候補が多い「な」「の」「を」などが現れた点で言葉のつながりが怪しくなりそうです。
そうやって見れば得られた文字列は確かに「な」「の」「を」のところで不自然になっていることが分かります。

今の時点でも課題は多そうですが、この方法にはさらに弱点があります。
もともとテキストの自動生成はチャットボット用に大きな辞書を作ることが目的でした。
しかし文字単位のマルコフ連鎖は元になるテキストが大きくなるほど生成できるテキストの質が下がるのです。

次の候補がいくつあるかのヒストグラムを大きさの違うテキストに対して調べてみます。
Fig.1で題材にした小説の冒頭 927Byte と、同じく 21kByte を取り出して次候補の数をヒストグラムにしたものをFig. 2に示します。

![Fig. 2. 文字単位のマルコフ連鎖のヒストグラム](./1gram.png)

大きなテキストを用いると、ヒストグラムの左端でピークが小さくなり、右に向かって裾野が長くなることが分かります。
左端が小さくなると元の単語がさらに細切れになり、裾野が広がると文脈がより無秩序にまざりやすくなります。これらが生成された文の質を低下させるのです。
文字単位でのマルコフ連鎖は「言語の種類によらず使える」ことが利点と言われています。
が、それは使い物になってからの話です。

## 次の次の文字は

文字単位でのマルコフ連鎖はあまり筋が良くないことが分かりました。
よく知られた改善策をいくつか見ていきます。まずは前の一文字だけを見て次の文字を決めるのではなく、二文字前まで見ることにしましょう。
考慮する範囲が大きくなれば、そのぶん元のテキストに沿った範囲でテキストを生成できるようになるはずです。
考慮する文字が一つの場合uni-gram、2つの場合はbi-gram、一般的にはn-gramと呼ばれます。
これに対応して、uni-gramを利用したマルコフ連鎖を1階のマルコフ連鎖、bi-gramでは2階のマルコフ連鎖、一般的にはn階のマルコフ連鎖と呼ばれます。
実際に得られたマルコフ連鎖の一部はこのようになっています。

```
'科学': ['者'], '学者': ['た'], '者た': ['ち'], 'たち': ['が'], 'ちが'
```


また次候補をヒストグラムにするとFig. 3のようになります。青がuni-gram(先行する一文字を考慮)、赤がbi-gram(先行する二文字を考慮)です。

![Fig. 3. 二文字を考慮したマルコフ連鎖のヒストグラム](./2gram.png)

Fig. 3ではどちらも21kByteのテキストを用いていますが、uni-gramに比べてbi-gramは次候補の数が1である左端のピークが大きくなっており、次候補の数が2以上になる裾野の面積が小さくなっています。
これはいずれもbi-gramではテキストの無秩序化が低減される一方で元のテキストをなぞるだけになる確率が大きくなっていることを示します。


## 次の形態素は

マルコフ連鎖の改善策として、もともと単語であったものは区切らないようにするという方法があります。これを実行するには分かち書きや形態素解析を利用します。
形態素解析にはMeCabを用い、前述の小説の冒頭21kByteについて文字のマルコフ連鎖と形態素のマルコフ連鎖をヒストグラムで比べてみます(Fig. 4)。

![Fig. 4. 形態素単位の1-gramのヒストグラム](./morpho-1gram.png)

すると、テキストのサイズが大きくても形態素のマルコフ連鎖は文字のマルコフ連鎖と比べて無秩序化が進んでいない様子が分かります。
また考慮する文字の数が増えるわけなので、高階のマルコフ連鎖、またはn-gramと同様の効果があります。




